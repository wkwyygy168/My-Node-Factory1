import requests
import re
import base64

def mega_mirror():
    # 1. ä½ çš„é•œåƒæºæ¸…å•
    sources = [
        "https://gist.githubusercontent.com/shuaidaoya/9e5cf2749c0ce79932dd9229d9b4162b/raw/all.yaml",
        "https://gist.githubusercontent.com/shuaidaoya/9e5cf2749c0ce79932dd9229d9b4162b/raw/base64.txt"
    ]
    
    all_nodes = []
    
    for url in sources:
        try:
            print(f"ğŸš€ æ­£åœ¨æ”¶å‰²: {url}")
            # å¢åŠ è¶…æ—¶å’Œ UAï¼Œæ¨¡æ‹Ÿæµè§ˆå™¨è®¿é—®
            headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
            response = requests.get(url, headers=headers, timeout=15)
            raw_text = response.text
            
            # --- æ ¸å¿ƒé€»è¾‘ Aï¼šæš´åŠ›æå–æ‰€æœ‰æ ‡å‡†é“¾æ¥ ---
            # åŒ¹é… vmess, vless, ss, ssr, trojan, hy2 ç­‰
            links = re.findall(r'(?:ss|ssr|vmess|vless|trojan|hy2|tuic|socks)://[^\s<>"\',;]+', raw_text, re.I)
            
            for link in links:
                if "vmess://" in link:
                    try:
                        # è‡ªåŠ¨å¤„ç† VMess å†…éƒ¨å¯èƒ½çš„ Base64 ç¼–ç 
                        b64_part = link.split("vmess://")[1].strip()
                        b64_part += "=" * (-len(b64_part) % 4)
                        decoded = base64.b64decode(b64_part).decode('utf-8', errors='ignore')
                        # å¦‚æœè§£å‡ºæ¥çš„ä¸œè¥¿è¿˜æ˜¯é“¾æ¥ï¼ˆå¥—å¨ƒï¼‰ï¼Œå†æ¬¡æå–
                        if "://" in decoded:
                            all_nodes.extend(re.findall(r'[a-zA-Z0-9]+://[^\s<>"\',;]+', decoded))
                        else:
                            all_nodes.append(link)
                    except:
                        all_nodes.append(link)
                else:
                    all_nodes.append(link)

            # --- æ ¸å¿ƒé€»è¾‘ Bï¼šå°è¯•å¯¹æ•´ä¸ªé¡µé¢è¿›è¡Œ Base64 è§£ç  (é’ˆå¯¹ base64.txt) ---
            try:
                # å°è¯•è¡¥é½å¹¶è§£ç 
                b64_content = raw_text.strip()
                b64_content += "=" * (-len(b64_content) % 4)
                decoded_page = base64.b64decode(b64_content).decode('utf-8', errors='ignore')
                if "://" in decoded_page:
                    b64_links = re.findall(r'(?:ss|ssr|vmess|vless|trojan|hy2|tuic|socks)://[^\s<>"\',;]+', decoded_page, re.I)
                    all_nodes.extend(b64_links)
            except:
                pass

        except Exception as e:
            print(f"âŒ æ”¶å‰² {url} å‡ºé”™: {e}")

    # --- æœ€ç»ˆå»é‡ ---
    # å½»åº•è§£å†³é‡å¤èŠ‚ç‚¹å †ç§¯é—®é¢˜
    unique_nodes = list(set(all_nodes))
    
    # --- å†™å…¥æ–‡ä»¶ ---
    with open("nodes.txt", "w", encoding="utf-8") as f:
        if unique_nodes:
            f.write("\n".join(unique_nodes))
            print(f"âœ¨ é•œåƒå¤§è·å…¨èƒœï¼å·²æˆåŠŸæ¬è¿å¹¶åˆå¹¶ {len(unique_nodes)} ä¸ªèŠ‚ç‚¹åˆ° nodes.txt")
        else:
            # ä¿åº•é˜²æ­¢ 0 bytes
            f.write("ss://YWVzLTI1Ni1jZmI6WG44aktkbURNMDBJZU8lIyQjZkpBTXRzRUFFVU9wSC9ZV1l0WXFERm5UMFNWQDEwMy4xODYuMTU1LjI3OjM4Mzg4#èŠ‚ç‚¹åŠ è½½ä¸­_è¯·ç¨ååˆ·æ–°")
            print("âš ï¸ æœªå‘ç°èŠ‚ç‚¹ï¼Œå·²å†™å…¥ä¿åº•æ•°æ®ã€‚")

if __name__ == "__main__":
    mega_mirror()
